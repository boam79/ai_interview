'use client';

import { useState, useEffect, useRef } from 'react';
import { motion } from 'framer-motion';
import { useRouter } from 'next/navigation';
import RecordButton, { RecordButtonState } from '@/components/voice-test/RecordButton';
import RealtimeTranscription from '@/components/voice-test/RealtimeTranscription';
import IntroductionGuide from '@/components/voice-test/IntroductionGuide';
import { fadeInUp, scaleIn } from '@/utils/animations';
import {
  requestMicrophoneAccess,
  startAudioStream,
  stopAudioStream,
  AudioCaptureState,
  getMicrophoneErrorMessage,
  isMicrophoneSupported,
} from '@/utils/audioCapture';
import { createAudioRecorder } from '@/utils/audioRecorder';
import { 
  startRealtimeTranscription, 
  simulateRealtimeTranscription,
  formatTranscriptionText,
  isStreamingSupported 
} from '@/utils/realtimeTranscription';

/**
 * Voice Test Page
 * 
 * User flow:
 * 1. Request microphone permission
 * 2. Show test sentence
 * 3. Record user speaking
 * 4. Send to Whisper API
 * 5. Display recognized text
 * 6. Allow retry or continue to next step
 */
export default function VoiceTestPage() {
  const router = useRouter();

  // Microphone permission state
  const [permissionGranted, setPermissionGranted] = useState<boolean>(false);
  const [permissionError, setPermissionError] = useState<string | null>(null);
  const [selectedMicrophoneInfo, setSelectedMicrophoneInfo] = useState<{
    label: string;
    deviceId: string;
    isBluetooth: boolean;
  } | null>(null);

  // Audio state
  const [audioCaptureState, setAudioCaptureState] = useState<AudioCaptureState | null>(null);
  const audioRecorderRef = useRef(createAudioRecorder({ maxDuration: 60000 })); // 60 seconds max

  // Recording state
  const [recordButtonState, setRecordButtonState] = useState<RecordButtonState>('idle');
  const [isRecording, setIsRecording] = useState<boolean>(false);

  // Transcription state
  const [recognizedText, setRecognizedText] = useState<string>('');
  const [transcriptionError, setTranscriptionError] = useState<string | null>(null);

  // Realtime transcription state
  const [realtimeText, setRealtimeText] = useState<string>('');
  const [isRealtimeProcessing, setIsRealtimeProcessing] = useState<boolean>(false);
  const realtimeControllerRef = useRef<AbortController | null>(null);

  // Introduction guide state
  const [showIntroductionGuide, setShowIntroductionGuide] = useState<boolean>(false);

  // Test sentence
  const testSentence = 'ÏïàÎÖïÌïòÏÑ∏Ïöî. Ï†ÄÎäî AI Î©¥Ï†ëÏùÑ Ï§ÄÎπÑÌïòÍ≥† ÏûàÏäµÎãàÎã§.';

  /**
   * Request microphone permission on mount
   */
  useEffect(() => {
    handleRequestPermission();
  }, []);

  /**
   * Cleanup on unmount
   */
  useEffect(() => {
    return () => {
      if (audioCaptureState) {
        stopAudioStream(audioCaptureState);
      }
      audioRecorderRef.current.cleanup();
      
      // Cancel realtime transcription if running
      if (realtimeControllerRef.current) {
        realtimeControllerRef.current.abort();
      }
    };
  }, [audioCaptureState]);

  /**
   * Request microphone permission (auto-select best microphone)
   */
  const handleRequestPermission = async () => {
    try {
      console.log('üé§ Requesting microphone permission...');

      // Check browser support
      if (!isMicrophoneSupported()) {
        throw new Error('Î∏åÎùºÏö∞Ï†ÄÍ∞Ä ÎßàÏù¥ÌÅ¨Î•º ÏßÄÏõêÌïòÏßÄ ÏïäÏäµÎãàÎã§.');
      }

      // Request permission (automatically selects best microphone)
      const { stream, microphoneInfo } = await requestMicrophoneAccess();
      
      // Start audio stream
      const captureState = startAudioStream(stream);
      setAudioCaptureState(captureState);
      setSelectedMicrophoneInfo(microphoneInfo);
      setPermissionGranted(true);
      setPermissionError(null);

      console.log('‚úÖ Microphone permission granted (auto-selected best device)');
      console.log('üé§ Selected microphone:', microphoneInfo);

    } catch (error: any) {
      console.error('‚ùå Microphone permission error:', error);
      setPermissionError(getMicrophoneErrorMessage(error));
      setPermissionGranted(false);
      setSelectedMicrophoneInfo(null);
    }
  };

  /**
   * Handle record button click
   */
  const handleRecordButtonClick = async () => {
    if (isRecording) {
      // Stop recording
      await handleStopRecording();
    } else {
      // Show introduction guide first
      setShowIntroductionGuide(true);
    }
  };

  /**
   * Handle start recording after guide
   */
  const handleStartRecordingFromGuide = () => {
    handleStartRecording();
  };

  /**
   * Start recording
   */
  const handleStartRecording = () => {
    try {
      if (!audioCaptureState || !audioCaptureState.stream) {
        throw new Error('Ïò§ÎîîÏò§ Ïä§Ìä∏Î¶ºÏùÑ ÏÇ¨Ïö©Ìï† Ïàò ÏóÜÏäµÎãàÎã§.');
      }

      console.log('üî¥ Starting recording...');

      // Clear previous results
      setRecognizedText('');
      setTranscriptionError(null);
      setRealtimeText('');

      // Start recording
      audioRecorderRef.current.startRecording(audioCaptureState.stream);
      setIsRecording(true);
      setRecordButtonState('recording');

    } catch (error: any) {
      console.error('‚ùå Recording start error:', error);
      alert(`ÎÖπÏùå ÏãúÏûë Ïò§Î•ò: ${error.message}`);
    }
  };

  /**
   * Stop recording and send to Whisper API
   */
  const handleStopRecording = async () => {
    try {
      console.log('üõë Stopping recording...');

      // Stop recording
      audioRecorderRef.current.stopRecording();
      setIsRecording(false);
      setRecordButtonState('processing');

      // Get recorded file
      const audioFile = audioRecorderRef.current.getRecordedFile('voice-test.webm');
      if (!audioFile) {
        throw new Error('ÎÖπÏùåÎêú Ïò§ÎîîÏò§Î•º Í∞ÄÏ†∏Ïò¨ Ïàò ÏóÜÏäµÎãàÎã§.');
      }

      console.log('üì§ Starting realtime transcription...');

      // Start realtime transcription
      setIsRealtimeProcessing(true);
      
      // Use regular transcription with typing effect (realtime API disabled)
      console.log('üì§ Using real-time streaming transcription...');
      await handleStreamingTranscription(audioFile);

    } catch (error: any) {
      console.error('‚ùå Transcription error:', error);
      setTranscriptionError(error.message || 'ÏùåÏÑ± Ïù∏Ïãù Ï§ë Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§.');
      setRecordButtonState('idle');
      audioRecorderRef.current.cleanup();
    }
  };

  /**
   * Handle streaming transcription
   */
  const handleStreamingTranscription = async (audioFile: File) => {
    try {
      console.log('üì§ Starting streaming transcription...');
      
      realtimeControllerRef.current = await startRealtimeTranscription(audioFile, {
        onTextUpdate: (deltaText, fullText) => {
          console.log('üìù Streaming delta:', deltaText);
          setRealtimeText(fullText);
        },
        onComplete: (finalText, duration) => {
          console.log('‚úÖ Streaming transcription completed:', finalText);
          setRecognizedText(finalText);
          setIsRealtimeProcessing(false);
          setRecordButtonState('idle');
          audioRecorderRef.current.cleanup();
        },
        onError: (error) => {
          console.error('‚ùå Streaming transcription error:', error);
          setTranscriptionError(error);
          setIsRealtimeProcessing(false);
          setRecordButtonState('idle');
          audioRecorderRef.current.cleanup();
        }
      });
      
    } catch (error: any) {
      console.error('‚ùå Streaming transcription setup error:', error);
      setTranscriptionError(error.message || 'Ïã§ÏãúÍ∞Ñ ÏùåÏÑ± Ïù∏Ïãù ÏÑ§Ï†ïÏóê Ïã§Ìå®ÌñàÏäµÎãàÎã§.');
      setIsRealtimeProcessing(false);
      setRecordButtonState('idle');
      audioRecorderRef.current.cleanup();
    }
  };

  /**
   * Handle regular (non-streaming) transcription
   */
  const handleRegularTranscription = async (audioFile: File) => {
    try {
      console.log('üì§ Sending audio to regular Whisper API...');

      // Send to Whisper API
      const formData = new FormData();
      formData.append('audio', audioFile);

      const response = await fetch('/api/voice-to-text', {
        method: 'POST',
        body: formData,
      });

      const result = await response.json();

      if (!response.ok || !result.success) {
        throw new Error(result.error || 'ÏùåÏÑ± Ïù∏ÏãùÏóê Ïã§Ìå®ÌñàÏäµÎãàÎã§.');
      }

      console.log('‚úÖ Regular transcription successful:', result.text);

      // Simulate realtime typing effect for better UX
      const formattedText = formatTranscriptionText(result.text);
      
      realtimeControllerRef.current = simulateRealtimeTranscription(formattedText, {
        onTextUpdate: (deltaText, fullText) => {
          setRealtimeText(fullText);
        },
        onComplete: (finalText, duration) => {
          console.log('‚úÖ Typing effect completed, setting recognized text:', finalText);
          setRecognizedText(finalText);
          setIsRealtimeProcessing(false);
          setRecordButtonState('idle');
          audioRecorderRef.current.cleanup();
        }
      }, 30); // Faster typing for demo
      
      // Î∞±ÏóÖ: ÌÉÄÏù¥Ìïë Ìö®Í≥ºÍ∞Ä 5Ï¥à Ïù¥ÏÉÅ Í±∏Î¶¨Î©¥ Í∞ïÏ†úÎ°ú ÏôÑÎ£å Ï≤òÎ¶¨
      setTimeout(() => {
        if (isRealtimeProcessing && !recognizedText) {
          console.log('‚ö†Ô∏è Typing effect timeout, forcing completion');
          setRecognizedText(formattedText);
          setIsRealtimeProcessing(false);
          setRecordButtonState('idle');
          audioRecorderRef.current.cleanup();
        }
      }, 5000);

    } catch (error: any) {
      console.error('‚ùå Regular transcription error:', error);
      setTranscriptionError(error.message || 'ÏùåÏÑ± Ïù∏ÏãùÏóê Ïã§Ìå®ÌñàÏäµÎãàÎã§.');
      setIsRealtimeProcessing(false);
      setRecordButtonState('idle');
      audioRecorderRef.current.cleanup();
    }
  };

  /**
   * Handle retry - reset everything for new test
   */
  const handleRetry = () => {
    setRecognizedText('');
    setTranscriptionError(null);
    setRealtimeText('');
    setIsRealtimeProcessing(false);
    setRecordButtonState('idle');
    
    // Cancel any ongoing transcription
    if (realtimeControllerRef.current) {
      realtimeControllerRef.current.abort();
      realtimeControllerRef.current = null;
    }
    
    audioRecorderRef.current.cleanup();
    console.log('üîÑ ÌÖåÏä§Ìä∏Î•º Îã§Ïãú ÏãúÏûëÌï©ÎãàÎã§.');
  };

  /**
   * Handle continue to next step
   */
  const handleContinue = () => {
    // Save voice test result
    if (typeof window !== 'undefined') {
      localStorage.setItem('voiceTestPassed', 'true');
      localStorage.setItem('voiceTestText', recognizedText);
    }
    
    // Navigate to voice interview page
    console.log('‚úÖ ÏùåÏÑ± ÌÖåÏä§Ìä∏ ÏôÑÎ£å! ÏùåÏÑ± Î©¥Ï†ëÏúºÎ°ú Ïù¥ÎèôÌï©ÎãàÎã§.');
    router.push('/voice-interview');
  };

  return (
    <div className="min-h-screen bg-white flex flex-col items-center justify-center p-2 sm:p-4 md:p-6 relative">
      <div className="w-full max-w-xs sm:max-w-lg md:max-w-2xl lg:max-w-4xl xl:max-w-6xl mx-auto flex flex-col items-center space-y-3 sm:space-y-4 md:space-y-6 lg:space-y-8">
        
        {/* Header */}
        <motion.div
          variants={fadeInUp}
          initial="initial"
          animate="animate"
          className="text-center space-y-2"
        >
          <h1 className="text-2xl sm:text-3xl md:text-4xl lg:text-5xl font-bold text-gray-900 dark:text-gray-100 text-center">
            ÏùåÏÑ± ÌÖåÏä§Ìä∏
          </h1>
          <p className="text-sm sm:text-base lg:text-lg text-gray-600 dark:text-gray-400 text-center">
            ÎßàÏù¥ÌÅ¨Í∞Ä Ï†ïÏÉÅÏ†ÅÏúºÎ°ú ÏûëÎèôÌïòÎäîÏßÄ ÌôïÏù∏Ìï©ÎãàÎã§
          </p>
        </motion.div>

        {/* Permission Error */}
        {permissionError && (
          <motion.div
            variants={scaleIn}
            initial="initial"
            animate="animate"
            className="glass-card bg-red-50/80 border-red-200 p-3 sm:p-4 md:p-6 rounded-2xl w-full mx-2 sm:mx-4"
          >
            <div className="flex items-start space-x-3">
              <div className="flex-shrink-0">
                <svg className="w-6 h-6 text-red-600" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                  <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M12 9v2m0 4h.01m-6.938 4h13.856c1.54 0 2.502-1.667 1.732-3L13.732 4c-.77-1.333-2.694-1.333-3.464 0L3.34 16c-.77 1.333.192 3 1.732 3z" />
                </svg>
              </div>
              <div className="flex-1">
                <h3 className="text-lg font-semibold text-red-900 mb-2">ÎßàÏù¥ÌÅ¨ Í∂åÌïú Ïò§Î•ò</h3>
                <p className="text-red-800 mb-4">{permissionError}</p>
                <button
                  onClick={handleRequestPermission}
                  className="glass-button-primary text-white px-6 py-2 rounded-lg"
                >
                  Îã§Ïãú ÏãúÎèÑ
                </button>
              </div>
            </div>
          </motion.div>
        )}

        {/* Main content (only show if permission granted) */}
        {permissionGranted && (
          <>
            {/* Test sentence card */}
            <motion.div
              variants={fadeInUp}
              initial="initial"
              animate="animate"
              transition={{ delay: 0.1 }}
              className="glass-card p-3 sm:p-4 md:p-6 lg:p-8 rounded-2xl w-full text-center mx-2 sm:mx-4"
            >
              <h2 className="text-lg sm:text-xl font-semibold text-gray-800 dark:text-gray-200 mb-3 sm:mb-4">
                ÏûêÍ∏∞ÏÜåÍ∞úÎ•º Ìï¥Ï£ºÏÑ∏Ïöî
              </h2>
              <p className="text-sm sm:text-base lg:text-lg text-gray-600 dark:text-gray-400 mb-3 sm:mb-4">
                Ïù¥Î¶Ñ, ÎÇòÏù¥, ÏßÅÏóÖ ÎòêÎäî Ï†ÑÍ≥µÏùÑ Í∞ÑÎã®Ìûà ÏÜåÍ∞úÌï¥Ï£ºÏÑ∏Ïöî
              </p>
              <div className="bg-gradient-to-r from-purple-50 to-blue-50 dark:from-purple-900/20 dark:to-blue-900/20 
                p-3 sm:p-4 rounded-xl border border-purple-200/50 dark:border-purple-700/50">
                <p className="text-xs sm:text-sm text-purple-700 dark:text-purple-300 font-medium mb-2">üí° ÏòàÏãú:</p>
                <p className="text-xs sm:text-sm lg:text-base text-gray-700 dark:text-gray-300 italic leading-relaxed">
                  "ÏïàÎÖïÌïòÏÑ∏Ïöî. Ï†ÄÎäî ÍπÄÏ≤†ÏàòÏûÖÎãàÎã§. Ïò¨Ìï¥ 25ÏÇ¥Ïù¥Í≥†, Ïª¥Ìì®ÌÑ∞Í≥µÌïôÏùÑ Ï†ÑÍ≥µÌïòÍ≥† ÏûàÏäµÎãàÎã§."
                </p>
              </div>
            </motion.div>

            {/* Microphone status */}
            {permissionGranted && selectedMicrophoneInfo && (
              <motion.div
                variants={fadeInUp}
                initial="initial"
                animate="animate"
                transition={{ delay: 0.15 }}
                className="w-full mx-2 sm:mx-4"
              >
                <div className="glass-card p-4 rounded-2xl text-center">
                  <div className="flex items-center justify-center space-x-2 text-gray-700 dark:text-gray-300 mb-2">
                    <span className="text-lg">{selectedMicrophoneInfo.isBluetooth ? 'üéß' : 'üé§'}</span>
                    <span className="text-sm font-medium">
                      {selectedMicrophoneInfo.isBluetooth ? 'Î∏îÎ£®Ìà¨Ïä§ Ïù¥Ïñ¥Ìè∞Ïù¥ ÏÑ†ÌÉùÎêòÏóàÏäµÎãàÎã§' : 'ÎßàÏù¥ÌÅ¨Í∞Ä ÏÑ†ÌÉùÎêòÏóàÏäµÎãàÎã§'}
                    </span>
                  </div>
                  <div className="bg-white/10 rounded-lg p-3 mb-2">
                    <p className="text-sm font-semibold text-gray-800 dark:text-gray-200">
                      {selectedMicrophoneInfo.label || 'Í∏∞Î≥∏ ÎßàÏù¥ÌÅ¨'}
                    </p>
                    <p className="text-xs text-gray-600 dark:text-gray-400 mt-1">
                      {selectedMicrophoneInfo.isBluetooth ? 'Î∏îÎ£®Ìà¨Ïä§ ÎîîÎ∞îÏù¥Ïä§' : 'ÏùºÎ∞ò ÎßàÏù¥ÌÅ¨'}
                    </p>
                    <p className="text-xs text-blue-600 dark:text-blue-400 mt-1">
                      ÏÉÅÌÉú: {selectedMicrophoneInfo.isBluetooth ? 'Î∏îÎ£®Ìà¨Ïä§ Ïó∞Í≤∞Îê®' : 'Ïú†ÏÑ† Ïó∞Í≤∞Îê®'}
                    </p>
                  </div>
                  <p className="text-xs text-gray-500 dark:text-gray-400">
                    {selectedMicrophoneInfo.isBluetooth 
                      ? 'üéß Î∏îÎ£®Ìà¨Ïä§ Ïù¥Ïñ¥Ìè∞ÏúºÎ°ú ÎÖπÏùåÎê©ÎãàÎã§' 
                      : 'üé§ ÏùºÎ∞ò ÎßàÏù¥ÌÅ¨Î°ú ÎÖπÏùåÎê©ÎãàÎã§'
                    }
                  </p>
                </div>
              </motion.div>
            )}


            {/* Realtime transcription window */}
            <motion.div
              variants={fadeInUp}
              initial="initial"
              animate="animate"
              transition={{ delay: 0.25 }}
              className="w-full mx-2 sm:mx-4"
            >
              <RealtimeTranscription
                isRecording={isRecording}
                currentText={realtimeText}
                isProcessing={isRealtimeProcessing}
              />
              
            </motion.div>

            {/* Record button */}
            <motion.div
              variants={scaleIn}
              initial="initial"
              animate="animate"
              transition={{ delay: 0.3 }}
              className="flex flex-col items-center space-y-4"
            >
              <RecordButton
                state={recordButtonState}
                onClick={handleRecordButtonClick}
                disabled={!permissionGranted}
              />
              
              <p className="text-sm text-gray-500 dark:text-gray-400 text-center max-w-md">
                Î≤ÑÌäºÏùÑ ÎàÑÎ•¥Î©¥ ÏïàÎÇ¥Ï∞ΩÏù¥ ÎÇòÌÉÄÎÇ©ÎãàÎã§. ÏûêÍ∏∞ÏÜåÍ∞úÎ•º ÎßêÌïú ÌõÑ Îã§Ïãú Î≤ÑÌäºÏùÑ ÎàåÎü¨Ï£ºÏÑ∏Ïöî.
              </p>
            </motion.div>

            {/* ÏùåÏÑ±Ïù∏Ïãù ÏôÑÎ£å ÌõÑ Î≤ÑÌäºÎì§ */}
            {recognizedText && !isRealtimeProcessing && (
              <motion.div
                initial={{ opacity: 0, y: 20 }}
                animate={{ opacity: 1, y: 0 }}
                className="w-full mx-2 sm:mx-4"
              >
                <div className="glass-card p-4 sm:p-6 rounded-2xl text-center">
                  <div className="flex items-center justify-center space-x-2 text-green-600 mb-4">
                    <svg className="w-6 h-6" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                      <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M5 13l4 4L19 7" />
                    </svg>
                    <h3 className="text-lg font-semibold">ÏùåÏÑ±Ïù∏Ïãù ÏôÑÎ£å!</h3>
                  </div>
                  
                  <div className="bg-white/10 rounded-lg p-3 mb-4">
                    <p className="text-sm text-gray-700 dark:text-gray-300">
                      <strong>Ïù∏ÏãùÎêú ÌÖçÏä§Ìä∏:</strong>
                    </p>
                    <p className="text-base font-medium text-gray-800 dark:text-gray-200 mt-1">
                      "{recognizedText}"
                    </p>
                  </div>
                  
                  <div className="flex flex-col sm:flex-row gap-3 justify-center">
                    <motion.button
                      whileHover={{ scale: 1.05 }}
                      whileTap={{ scale: 0.95 }}
                      onClick={handleRetry}
                      className="px-6 py-3 rounded-xl bg-white/10 hover:bg-white/20 text-gray-700 dark:text-gray-300 font-semibold transition-all duration-300 border border-white/20"
                    >
                      üîÑ Îã§Ïãú ÌÖåÏä§Ìä∏
                    </motion.button>
                    
                    <motion.button
                      whileHover={{ scale: 1.05 }}
                      whileTap={{ scale: 0.95 }}
                      onClick={handleContinue}
                      className="px-6 py-3 rounded-xl bg-gradient-to-r from-purple-600 to-pink-600 hover:from-purple-700 hover:to-pink-700 text-white font-semibold transition-all duration-300 shadow-lg"
                    >
                      ‚úÖ Îã§Ïùå Îã®Í≥Ñ
                    </motion.button>
                  </div>
                </div>
              </motion.div>
            )}

            {/* Transcription error */}
            {transcriptionError && (
              <motion.div
                initial={{ opacity: 0, y: -10 }}
                animate={{ opacity: 1, y: 0 }}
                className="glass-card bg-red-50/80 border-red-200 p-3 sm:p-4 md:p-6 rounded-2xl w-full mx-2 sm:mx-4"
              >
                <div className="flex items-start space-x-3">
                  <svg className="w-6 h-6 text-red-600 flex-shrink-0" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                    <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M6 18L18 6M6 6l12 12" />
                  </svg>
                  <div className="flex-1">
                    <h3 className="text-lg font-semibold text-red-900 mb-2">Ïù∏Ïãù Ïã§Ìå®</h3>
                    <p className="text-red-800 mb-4">{transcriptionError}</p>
                    <button
                      onClick={handleRetry}
                      className="glass-button text-gray-700 px-6 py-2 rounded-lg"
                    >
                      Îã§Ïãú ÏãúÎèÑ
                    </button>
                  </div>
                </div>
              </motion.div>
            )}

          </>
        )}

        {/* Introduction Guide Popup */}
        <IntroductionGuide
          isOpen={showIntroductionGuide}
          onClose={() => setShowIntroductionGuide(false)}
          onStartRecording={handleStartRecordingFromGuide}
        />

        {/* Helper text */}
        <motion.div
          initial={{ opacity: 0 }}
          animate={{ opacity: 1 }}
          transition={{ delay: 0.5 }}
          className="text-center text-sm text-gray-500 dark:text-gray-400 space-y-2"
        >
          <p>üí° ÌåÅ: Ï°∞Ïö©Ìïú ÌôòÍ≤ΩÏóêÏÑú ÌÖåÏä§Ìä∏ÌïòÎ©¥ Îçî Ï†ïÌôïÌï©ÎãàÎã§.</p>
          <p>üîí ÎÖπÏùåÎêú ÏùåÏÑ±ÏùÄ Î∂ÑÏÑù ÌõÑ Ï¶âÏãú ÏÇ≠Ï†úÎê©ÎãàÎã§.</p>
        </motion.div>

      </div>
    </div>
  );
}

