'use client';

import { useState, useEffect, useRef } from 'react';
import { motion } from 'framer-motion';
import { useRouter } from 'next/navigation';
import RecordButton, { RecordButtonState } from '@/components/voice-test/RecordButton';
import RealtimeTranscription from '@/components/voice-test/RealtimeTranscription';
import IntroductionGuide from '@/components/voice-test/IntroductionGuide';
import { fadeInUp, scaleIn } from '@/utils/animations';
import {
  requestMicrophoneAccess,
  startAudioStream,
  stopAudioStream,
  AudioCaptureState,
  getMicrophoneErrorMessage,
  isMicrophoneSupported,
} from '@/utils/audioCapture';
import { createAudioRecorder } from '@/utils/audioRecorder';
import { 
  startRealtimeTranscription, 
  simulateRealtimeTranscription,
  formatTranscriptionText,
  isStreamingSupported 
} from '@/utils/realtimeTranscription';

/**
 * Voice Test Page
 * 
 * User flow:
 * 1. Request microphone permission
 * 2. Show test sentence
 * 3. Record user speaking
 * 4. Send to Whisper API
 * 5. Display recognized text
 * 6. Allow retry or continue to next step
 */
export default function VoiceTestPage() {
  const router = useRouter();

  // Microphone permission state
  const [permissionGranted, setPermissionGranted] = useState<boolean>(false);
  const [permissionError, setPermissionError] = useState<string | null>(null);
  const [selectedMicrophoneInfo, setSelectedMicrophoneInfo] = useState<{
    label: string;
    deviceId: string;
    isBluetooth: boolean;
  } | null>(null);

  // Audio state
  const [audioCaptureState, setAudioCaptureState] = useState<AudioCaptureState | null>(null);
  const audioRecorderRef = useRef(createAudioRecorder({ maxDuration: 60000 })); // 60 seconds max

  // Recording state
  const [recordButtonState, setRecordButtonState] = useState<RecordButtonState>('idle');
  const [isRecording, setIsRecording] = useState<boolean>(false);

  // Transcription state
  const [recognizedText, setRecognizedText] = useState<string>('');
  const [transcriptionError, setTranscriptionError] = useState<string | null>(null);

  // Realtime transcription state
  const [realtimeText, setRealtimeText] = useState<string>('');
  const [isRealtimeProcessing, setIsRealtimeProcessing] = useState<boolean>(false);
  const realtimeControllerRef = useRef<AbortController | null>(null);

  // Introduction guide state
  const [showIntroductionGuide, setShowIntroductionGuide] = useState<boolean>(false);

  // Test sentence
  const testSentence = 'ì•ˆë…•í•˜ì„¸ìš”. ì €ëŠ” AI ë©´ì ‘ì„ ì¤€ë¹„í•˜ê³  ìˆìŠµë‹ˆë‹¤.';

  /**
   * Request microphone permission on mount
   */
  useEffect(() => {
    handleRequestPermission();
  }, []);

  /**
   * Cleanup on unmount
   */
  useEffect(() => {
    return () => {
      if (audioCaptureState) {
        stopAudioStream(audioCaptureState);
      }
      audioRecorderRef.current.cleanup();
      
      // Cancel realtime transcription if running
      if (realtimeControllerRef.current) {
        realtimeControllerRef.current.abort();
      }
    };
  }, [audioCaptureState]);

  /**
   * Request microphone permission (auto-select best microphone)
   */
  const handleRequestPermission = async () => {
    try {
      console.log('ğŸ¤ Requesting microphone permission...');

      // Check browser support
      if (!isMicrophoneSupported()) {
        throw new Error('ë¸Œë¼ìš°ì €ê°€ ë§ˆì´í¬ë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.');
      }

      // Request permission (automatically selects best microphone)
      const { stream, microphoneInfo } = await requestMicrophoneAccess();
      
      // Start audio stream
      const captureState = startAudioStream(stream);
      setAudioCaptureState(captureState);
      setSelectedMicrophoneInfo(microphoneInfo);
      setPermissionGranted(true);
      setPermissionError(null);

      console.log('âœ… Microphone permission granted (auto-selected best device)');
      console.log('ğŸ¤ Selected microphone:', microphoneInfo);

    } catch (error: any) {
      console.error('âŒ Microphone permission error:', error);
      setPermissionError(getMicrophoneErrorMessage(error));
      setPermissionGranted(false);
      setSelectedMicrophoneInfo(null);
    }
  };

  /**
   * Handle record button click
   */
  const handleRecordButtonClick = async () => {
    if (isRecording) {
      // Stop recording
      await handleStopRecording();
    } else {
      // Show introduction guide first
      setShowIntroductionGuide(true);
    }
  };

  /**
   * Handle start recording after guide
   */
  const handleStartRecordingFromGuide = () => {
    handleStartRecording();
  };

  /**
   * Start recording
   */
  const handleStartRecording = () => {
    try {
      if (!audioCaptureState || !audioCaptureState.stream) {
        throw new Error('ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
      }

      console.log('ğŸ”´ Starting recording...');

      // Clear previous results
      setRecognizedText('');
      setTranscriptionError(null);
      setRealtimeText('');

      // Start recording
      audioRecorderRef.current.startRecording(audioCaptureState.stream);
      setIsRecording(true);
      setRecordButtonState('recording');

    } catch (error: any) {
      console.error('âŒ Recording start error:', error);
      alert(`ë…¹ìŒ ì‹œì‘ ì˜¤ë¥˜: ${error.message}`);
    }
  };

  /**
   * Stop recording and send to Whisper API
   */
  const handleStopRecording = async () => {
    try {
      console.log('ğŸ›‘ Stopping recording...');

      // Stop recording
      audioRecorderRef.current.stopRecording();
      setIsRecording(false);
      setRecordButtonState('processing');

      // Get recorded file
      const audioFile = audioRecorderRef.current.getRecordedFile('voice-test.webm');
      if (!audioFile) {
        throw new Error('ë…¹ìŒëœ ì˜¤ë””ì˜¤ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
      }

      console.log('ğŸ“¤ Starting realtime transcription...');

      // Start realtime transcription
      setIsRealtimeProcessing(true);
      
      // Use regular transcription with typing effect (realtime API disabled)
      console.log('ğŸ“¤ Using real-time streaming transcription...');
      await handleStreamingTranscription(audioFile);

    } catch (error: any) {
      console.error('âŒ Transcription error:', error);
      setTranscriptionError(error.message || 'ìŒì„± ì¸ì‹ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.');
      setRecordButtonState('idle');
      audioRecorderRef.current.cleanup();
    }
  };

  /**
   * Handle streaming transcription
   */
  const handleStreamingTranscription = async (audioFile: File) => {
    try {
      console.log('ğŸ“¤ Starting streaming transcription...');
      
      realtimeControllerRef.current = await startRealtimeTranscription(audioFile, {
        onTextUpdate: (deltaText, fullText) => {
          console.log('ğŸ“ Streaming delta:', deltaText);
          setRealtimeText(fullText);
        },
        onComplete: (finalText, duration) => {
          console.log('âœ… Streaming transcription completed:', finalText);
          setRecognizedText(finalText);
          setIsRealtimeProcessing(false);
          setRecordButtonState('idle');
          audioRecorderRef.current.cleanup();
        },
        onError: (error) => {
          console.error('âŒ Streaming transcription error:', error);
          setTranscriptionError(error);
          setIsRealtimeProcessing(false);
          setRecordButtonState('idle');
          audioRecorderRef.current.cleanup();
        }
      });
      
    } catch (error: any) {
      console.error('âŒ Streaming transcription setup error:', error);
      setTranscriptionError(error.message || 'ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹ ì„¤ì •ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
      setIsRealtimeProcessing(false);
      setRecordButtonState('idle');
      audioRecorderRef.current.cleanup();
    }
  };

  /**
   * Handle regular (non-streaming) transcription
   */
  const handleRegularTranscription = async (audioFile: File) => {
    try {
      console.log('ğŸ“¤ Sending audio to regular Whisper API...');

      // Send to Whisper API
      const formData = new FormData();
      formData.append('audio', audioFile);

      const response = await fetch('/api/voice-to-text', {
        method: 'POST',
        body: formData,
      });

      const result = await response.json();

      if (!response.ok || !result.success) {
        throw new Error(result.error || 'ìŒì„± ì¸ì‹ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
      }

      console.log('âœ… Regular transcription successful:', result.text);

      // Simulate realtime typing effect for better UX
      const formattedText = formatTranscriptionText(result.text);
      
      realtimeControllerRef.current = simulateRealtimeTranscription(formattedText, {
        onTextUpdate: (deltaText, fullText) => {
          setRealtimeText(fullText);
        },
        onComplete: (finalText, duration) => {
          console.log('âœ… Typing effect completed, setting recognized text:', finalText);
          setRecognizedText(finalText);
          setIsRealtimeProcessing(false);
          setRecordButtonState('idle');
          audioRecorderRef.current.cleanup();
        }
      }, 30); // Faster typing for demo
      
      // ë°±ì—…: íƒ€ì´í•‘ íš¨ê³¼ê°€ 5ì´ˆ ì´ìƒ ê±¸ë¦¬ë©´ ê°•ì œë¡œ ì™„ë£Œ ì²˜ë¦¬
      setTimeout(() => {
        if (isRealtimeProcessing && !recognizedText) {
          console.log('âš ï¸ Typing effect timeout, forcing completion');
          setRecognizedText(formattedText);
          setIsRealtimeProcessing(false);
          setRecordButtonState('idle');
          audioRecorderRef.current.cleanup();
        }
      }, 5000);

    } catch (error: any) {
      console.error('âŒ Regular transcription error:', error);
      setTranscriptionError(error.message || 'ìŒì„± ì¸ì‹ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
      setIsRealtimeProcessing(false);
      setRecordButtonState('idle');
      audioRecorderRef.current.cleanup();
    }
  };

  /**
   * Handle retry - reset everything for new test
   */
  const handleRetry = () => {
    setRecognizedText('');
    setTranscriptionError(null);
    setRealtimeText('');
    setIsRealtimeProcessing(false);
    setRecordButtonState('idle');
    
    // Cancel any ongoing transcription
    if (realtimeControllerRef.current) {
      realtimeControllerRef.current.abort();
      realtimeControllerRef.current = null;
    }
    
    audioRecorderRef.current.cleanup();
    console.log('ğŸ”„ í…ŒìŠ¤íŠ¸ë¥¼ ë‹¤ì‹œ ì‹œì‘í•©ë‹ˆë‹¤.');
  };

  /**
   * Handle continue to next step
   */
  const handleContinue = () => {
    // Save voice test result
    if (typeof window !== 'undefined') {
      localStorage.setItem('voiceTestPassed', 'true');
      localStorage.setItem('voiceTestText', recognizedText);
    }
    
    // Navigate to voice interview page
    console.log('âœ… ìŒì„± í…ŒìŠ¤íŠ¸ ì™„ë£Œ! ìŒì„± ë©´ì ‘ìœ¼ë¡œ ì´ë™í•©ë‹ˆë‹¤.');
    router.push('/voice-interview');
  };

  return (
    <div className="min-h-screen bg-white flex flex-col items-center justify-center p-2 sm:p-4 md:p-6 relative">
      <div className="w-full max-w-xs sm:max-w-lg md:max-w-2xl lg:max-w-4xl xl:max-w-6xl mx-auto flex flex-col items-center space-y-3 sm:space-y-4 md:space-y-6 lg:space-y-8">
        
        {/* Header */}
        <motion.div
          variants={fadeInUp}
          initial="initial"
          animate="animate"
          className="text-center space-y-2"
        >
          <h1 className="text-2xl sm:text-3xl md:text-4xl lg:text-5xl font-bold text-gray-900 dark:text-gray-100 text-center">
            ìŒì„± í…ŒìŠ¤íŠ¸
          </h1>
          <p className="text-sm sm:text-base lg:text-lg text-gray-600 dark:text-gray-400 text-center">
            ë§ˆì´í¬ê°€ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤
          </p>
        </motion.div>

        {/* Permission Error */}
        {permissionError && (
          <motion.div
            variants={scaleIn}
            initial="initial"
            animate="animate"
            className="glass-card bg-red-50/80 border-red-200 p-3 sm:p-4 md:p-6 rounded-2xl w-full mx-2 sm:mx-4"
          >
            <div className="flex items-start space-x-3">
              <div className="flex-shrink-0">
                <svg className="w-6 h-6 text-red-600" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                  <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M12 9v2m0 4h.01m-6.938 4h13.856c1.54 0 2.502-1.667 1.732-3L13.732 4c-.77-1.333-2.694-1.333-3.464 0L3.34 16c-.77 1.333.192 3 1.732 3z" />
                </svg>
              </div>
              <div className="flex-1">
                <h3 className="text-lg font-semibold text-red-900 mb-2">ë§ˆì´í¬ ê¶Œí•œ ì˜¤ë¥˜</h3>
                <p className="text-red-800 mb-4">{permissionError}</p>
                <button
                  onClick={handleRequestPermission}
                  className="glass-button-primary text-white px-6 py-2 rounded-lg"
                >
                  ë‹¤ì‹œ ì‹œë„
                </button>
              </div>
            </div>
          </motion.div>
        )}

        {/* Main content (only show if permission granted) */}
        {permissionGranted && (
          <>
            {/* Test sentence card */}
            <motion.div
              variants={fadeInUp}
              initial="initial"
              animate="animate"
              transition={{ delay: 0.1 }}
              className="glass-card p-3 sm:p-4 md:p-6 lg:p-8 rounded-2xl w-full text-center mx-2 sm:mx-4"
            >
              <h2 className="text-lg sm:text-xl font-semibold text-gray-800 dark:text-gray-200 mb-3 sm:mb-4">
                ìê¸°ì†Œê°œë¥¼ í•´ì£¼ì„¸ìš”
              </h2>
              <p className="text-sm sm:text-base lg:text-lg text-gray-600 dark:text-gray-400 mb-3 sm:mb-4">
                ì´ë¦„, ë‚˜ì´, ì§ì—… ë˜ëŠ” ì „ê³µì„ ê°„ë‹¨íˆ ì†Œê°œí•´ì£¼ì„¸ìš”
              </p>
              <div className="bg-gradient-to-r from-purple-50 to-blue-50 dark:from-purple-900/20 dark:to-blue-900/20 
                p-3 sm:p-4 rounded-xl border border-purple-200/50 dark:border-purple-700/50">
                <p className="text-xs sm:text-sm text-purple-700 dark:text-purple-300 font-medium mb-2">ğŸ’¡ ì˜ˆì‹œ:</p>
                <p className="text-xs sm:text-sm lg:text-base text-gray-700 dark:text-gray-300 italic leading-relaxed">
                  "ì•ˆë…•í•˜ì„¸ìš”. ì €ëŠ” ê¹€ì² ìˆ˜ì…ë‹ˆë‹¤. ì˜¬í•´ 25ì‚´ì´ê³ , ì»´í“¨í„°ê³µí•™ì„ ì „ê³µí•˜ê³  ìˆìŠµë‹ˆë‹¤."
                </p>
              </div>
            </motion.div>

            {/* Microphone status */}
            {permissionGranted && selectedMicrophoneInfo && (
              <motion.div
                variants={fadeInUp}
                initial="initial"
                animate="animate"
                transition={{ delay: 0.15 }}
                className="w-full mx-2 sm:mx-4"
              >
                <div className="glass-card p-4 rounded-2xl text-center">
                  <div className="flex items-center justify-center space-x-2 text-gray-700 dark:text-gray-300 mb-2">
                    <span className="text-lg">{selectedMicrophoneInfo.isBluetooth ? 'ğŸ§' : 'ğŸ¤'}</span>
                    <span className="text-sm font-medium">
                      {selectedMicrophoneInfo.isBluetooth ? 'ë¸”ë£¨íˆ¬ìŠ¤ ì´ì–´í°ì´ ì„ íƒë˜ì—ˆìŠµë‹ˆë‹¤' : 'ë§ˆì´í¬ê°€ ì„ íƒë˜ì—ˆìŠµë‹ˆë‹¤'}
                    </span>
                  </div>
                  <div className="bg-white/10 rounded-lg p-3 mb-2">
                    <p className="text-sm font-semibold text-gray-800 dark:text-gray-200">
                      {selectedMicrophoneInfo.label || 'ê¸°ë³¸ ë§ˆì´í¬'}
                    </p>
                    <p className="text-xs text-gray-600 dark:text-gray-400 mt-1">
                      {selectedMicrophoneInfo.isBluetooth ? 'ë¸”ë£¨íˆ¬ìŠ¤ ë””ë°”ì´ìŠ¤' : 'ì¼ë°˜ ë§ˆì´í¬'}
                    </p>
                    <p className="text-xs text-blue-600 dark:text-blue-400 mt-1">
                      ìƒíƒœ: {selectedMicrophoneInfo.isBluetooth ? 'ë¸”ë£¨íˆ¬ìŠ¤ ì—°ê²°ë¨' : 'ìœ ì„  ì—°ê²°ë¨'}
                    </p>
                  </div>
                  <p className="text-xs text-gray-500 dark:text-gray-400">
                    {selectedMicrophoneInfo.isBluetooth 
                      ? 'ğŸ§ ë¸”ë£¨íˆ¬ìŠ¤ ì´ì–´í°ìœ¼ë¡œ ë…¹ìŒë©ë‹ˆë‹¤' 
                      : 'ğŸ¤ ì¼ë°˜ ë§ˆì´í¬ë¡œ ë…¹ìŒë©ë‹ˆë‹¤'
                    }
                  </p>
                </div>
              </motion.div>
            )}


            {/* Realtime transcription window */}
            <motion.div
              variants={fadeInUp}
              initial="initial"
              animate="animate"
              transition={{ delay: 0.25 }}
              className="w-full mx-2 sm:mx-4"
            >
              <RealtimeTranscription
                isRecording={isRecording}
                currentText={realtimeText}
                isProcessing={isRealtimeProcessing}
              />
              
            </motion.div>

            {/* Record button */}
            <motion.div
              variants={scaleIn}
              initial="initial"
              animate="animate"
              transition={{ delay: 0.3 }}
              className="flex flex-col items-center space-y-4"
            >
              <RecordButton
                state={recordButtonState}
                onClick={handleRecordButtonClick}
                disabled={!permissionGranted}
              />
              
              <p className="text-sm text-gray-500 dark:text-gray-400 text-center max-w-md">
                ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ ì•ˆë‚´ì°½ì´ ë‚˜íƒ€ë‚©ë‹ˆë‹¤. ìê¸°ì†Œê°œë¥¼ ë§í•œ í›„ ë‹¤ì‹œ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.
              </p>
            </motion.div>

            {/* ìŒì„±ì¸ì‹ ì™„ë£Œ í›„ ë²„íŠ¼ë“¤ */}
            {recognizedText && !isRealtimeProcessing && (
              <motion.div
                initial={{ opacity: 0, y: 20 }}
                animate={{ opacity: 1, y: 0 }}
                className="w-full mx-2 sm:mx-4"
              >
                <div className="glass-card p-4 sm:p-6 rounded-2xl text-center">
                  <div className="flex items-center justify-center space-x-2 text-green-600 mb-4">
                    <svg className="w-6 h-6" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                      <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M5 13l4 4L19 7" />
                    </svg>
                    <h3 className="text-lg font-semibold">ìŒì„±ì¸ì‹ ì™„ë£Œ!</h3>
                  </div>
                  
                  <div className="bg-white/10 rounded-lg p-3 mb-4">
                    <p className="text-sm text-gray-700 dark:text-gray-300">
                      <strong>ì¸ì‹ëœ í…ìŠ¤íŠ¸:</strong>
                    </p>
                    <p className="text-base font-medium text-gray-800 dark:text-gray-200 mt-1">
                      "{recognizedText}"
                    </p>
                  </div>
                  
                  <div className="flex flex-col sm:flex-row gap-3 justify-center">
                    <motion.button
                      whileHover={{ scale: 1.05 }}
                      whileTap={{ scale: 0.95 }}
                      onClick={handleRetry}
                      className="px-6 py-3 rounded-xl bg-white/10 hover:bg-white/20 text-gray-700 dark:text-gray-300 font-semibold transition-all duration-300 border border-white/20"
                    >
                      ğŸ”„ ë‹¤ì‹œ í…ŒìŠ¤íŠ¸
                    </motion.button>
                    
                    <motion.button
                      whileHover={{ scale: 1.05 }}
                      whileTap={{ scale: 0.95 }}
                      onClick={handleContinue}
                      className="px-6 py-3 rounded-xl bg-gradient-to-r from-purple-600 to-pink-600 hover:from-purple-700 hover:to-pink-700 text-white font-semibold transition-all duration-300 shadow-lg"
                    >
                      âœ… ë‹¤ìŒ ë‹¨ê³„
                    </motion.button>
                  </div>
                </div>
              </motion.div>
            )}

            {/* Transcription error */}
            {transcriptionError && (
              <motion.div
                initial={{ opacity: 0, y: -10 }}
                animate={{ opacity: 1, y: 0 }}
                className="glass-card bg-red-50/80 border-red-200 p-3 sm:p-4 md:p-6 rounded-2xl w-full mx-2 sm:mx-4"
              >
                <div className="flex items-start space-x-3">
                  <svg className="w-6 h-6 text-red-600 flex-shrink-0" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                    <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M6 18L18 6M6 6l12 12" />
                  </svg>
                  <div className="flex-1">
                    <h3 className="text-lg font-semibold text-red-900 mb-2">ì¸ì‹ ì‹¤íŒ¨</h3>
                    <p className="text-red-800 mb-4">{transcriptionError}</p>
                    <button
                      onClick={handleRetry}
                      className="glass-button text-gray-700 px-6 py-2 rounded-lg"
                    >
                      ë‹¤ì‹œ ì‹œë„
                    </button>
                  </div>
                </div>
              </motion.div>
            )}

          </>
        )}

        {/* Introduction Guide Popup */}
        <IntroductionGuide
          isOpen={showIntroductionGuide}
          onClose={() => setShowIntroductionGuide(false)}
          onStartRecording={handleStartRecordingFromGuide}
        />

        {/* Helper text */}
        <motion.div
          initial={{ opacity: 0 }}
          animate={{ opacity: 1 }}
          transition={{ delay: 0.5 }}
          className="text-center text-sm text-gray-500 dark:text-gray-400 space-y-2"
        >
          <p>ğŸ’¡ íŒ: ì¡°ìš©í•œ í™˜ê²½ì—ì„œ í…ŒìŠ¤íŠ¸í•˜ë©´ ë” ì •í™•í•©ë‹ˆë‹¤.</p>
          <p>ğŸ”’ ë…¹ìŒëœ ìŒì„±ì€ ë¶„ì„ í›„ ì¦‰ì‹œ ì‚­ì œë©ë‹ˆë‹¤.</p>
        </motion.div>

      </div>
    </div>
  );
}

